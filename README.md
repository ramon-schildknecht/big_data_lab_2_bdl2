# Big Data Lab 2
The overall goal was to  set up a Hadoop platform on Ubuntu, get a big data file, process it trough the data pipeline into Hadoop Distributed File System and answer defined questions with different technologies (pySpark, Spark SQL and more). 

One can get an idea from the file *Zeppelin-Bericht Schritt-f√ºr-Schritt Ramon Schildknecht.pdf*.
Fast readers get an idea from the file *Management Summary.pdf*.
All results can be furthermore explored within the *Zeppelin_Report_Rohdatei.json* file. One just needs to import it into Zeppelin.

This repo stores the necessary documenting pictures for the project, too. These files can be found in the *pictures* folder.
